
# [0.Quotes Scraper](https://github.com/ashwinshetgaonkar/Web-Quotes-Scraper)
Web scraping or web data extraction is used for extracting data from websites,this involves fetching data and extracting/parsing required info from it. Fetching is the downloading of a page (which a browser does when a user views a page).

* Implemented Web Scraping to extract data from static sites.
* Used `requests` and `BeautifulSoup` libraries to perform the web scraping.
* The project involved extracting the names of all topics of quotes and then scraping quotes along with their author name for all topics
  previously scraped.<br>
<!-- * Deployed the project using streamlit as a Web app. -->
* Tech stack used:`Python,requests,BeautifulSoup,pandas`.<br>
<!--   [To view the web app](https://share.streamlit.io/ashwinshetgaonkar/web-quotes-scraper/main/app.py) -->

  
# [1. Predict Price of Old Car](https://github.com/karanchinch10/Oldcar_Sell_Regression)                                      
 
Now a day many peoples prefer to <strong>buy second hand car instead of buying new one</strong>, as its better investment option where we get almost <strong>30-40% discount</strong>. but main question here is how seller will know <strong>actual selling price of old car</strong> base on car features or which factors play major roles?? So to solve this complex problem, I have build <strong>ML model</strong> which predict <strong>estimated price of car</strong> base on given input features as <strong>brand,KM drive,Power,Year and so on..

* Completed stepwise <strong>EDA (Exploratory Data Analysis)</strong> and visualization to get data insight & to know <strong>important features also their correlation</strong> with car price
* Done <strong>Feature Engineering</strong> includes <strong>Features extraction & Features construction</strong> based on my domian knowledge & visualization
* <strong>Train model</strong> with multiple regression algorithms then Analysed & compare performance of differents models based of <strong>accuracy and complexity</strong>
* Got well accuracy by <strong>RandomForestRegressor(cross validation-around 90%)</strong>
* <strong>Build Web App</strong> using streamlit and <strong>deploy</strong> model 
* Tech Tools:`Python,Numpy,Pandas,sklearn,matplotllib,seaborn,html,css`.
* * [View on kaggle](https://www.kaggle.com/code/karanchinchpure/predict-price-of-used-cars-regression-problem) üíù
  * [Web App](https://karanchinch10-oldcar-sell-streamlit-app-p6gwqq.streamlitapp.com) üíù
  

# [2. Bank Marketing Campaign](https://github.com/karanchinch10/Bank-Marketing-Campaign-ML)
<strong>Marketing campaigns</strong> are sets of strategic activities that promote a <strong>business‚Äôs goal</strong> or objective also can be used to promote a product, service, or any brand as a whole. The project is focus on analysis of <strong>Bank Marketing</strong> dataset which contains data of customers details (Personal + Banking) and aims to get useful insights from data. By understanding important features and <strong>patterns of target customers</strong> which can help to get best strategies to improve for the next marketing campaign 
* Build Model which predict either a new customer will accept a deposit offer or not
* Done <strong>EDA & Data Correction</strong> and Handle outliers 
* Visualize data to know pattern of target customers by their previuos campaign deatils includes contact duration,type,no of contact perform, also banking details & so on..
* <strong>RandomForest & XG boost Perform best (R2score 86%)</strong> after Train and Evaluate model performance based on accuracy, R2 score & complexity 
* Build <strong>Pipeline</strong> for <strong>deployment</strong> session & Deploy the model  
*  Tech stack used:`Python,pandas,matplotlib,seaborn,numpy,html,css`.
* * [View on kaggle](https://www.kaggle.com/code/karanchinchpure/bank-marketing-who-will-subscribe-for-deposit) üíù
  * [Web App](https://github.com/karanchinch10/Bank-Marketing-Campaign-ML) üíù
   


<!-- # [4.Road Deaths Analysis](https://github.com/ashwinshetgaonkar/Data-Visualization-Projects/tree/main/Road%20Deaths%20Analysis)
* The Dataset contains information of number of deaths in various regions of the World from 1990-2019,along with other data like historical population,region code,Side of driving.

* My objective for this Project was to visualize the available data to draw insights from it which are not perceived just by reading through an excel/csv file.
* Here I have visualized the number of deaths using various plots to gain various insights from the data.
* From this I can easily state the regions with maximum,mean deaths,year in which max deaths occured and many more.<br>
  [To view on kaggle](https://www.kaggle.com/code/ashwinshetgaonkar/road-deaths-data-visualization-seaborn) -->
  


# [4. Visualization of Google Playstore Apps](https://github.com/ashwinshetgaonkar/Estimate-Mechanical-Properties-of-Steel-compostions)
<strong>Google Play Store</strong> team is about to launch a new feature wherein, certain apps higher priority in recommendations sections</strong> (‚ÄúSimilar apps‚Äù,‚ÄúNew and updated games‚Äù) that are promising, are boosted in visibility also in search results visibility. This feature will help bring more attention to <strong>newer apps that have the potential.</strong>

* Perform <strong>EDA, Data cleaning and Data correction on raw data</strong> 
* Done <strong>visualization</strong>by various plots to draw useful insight from data and which will help for <strong>decision making</strong> like
1. <strong>Total No of apps</strong> of all category (like games,sports,medical,education,beauty..etc) 
2. Which <strong>category</strong> has <strong>highest demand</strong>, rating, installation or reviews?
3. Total <strong>percentages of free and paid apps</strong> available in glapy store
4. Is there is any <strong>relation of apps rating and reviews with their installation?</strong>
* Tech stack used : `Python, numpy, pandas, matplotlib, seaborn.`
* * [View on kaggle](https://www.kaggle.com/code/karanchinchpure/iris-classification-problem-eda) üíù
  * [View on Github](https://github.com/karanchinch10/IRIS_Classification) üíù
 

# [5. Bank Management Web App](https://github.com/ashwinshetgaonkar/Movie-Rating-Sentiment-Analysis)
<h4><strong>Python | Flask | SQL | HTML | CSS </strong></h4> 

 I have made<strong> Flask Project of Bank Management Web Application System</strong> designed for <strong>customer/bank holder</strong> to get all <strong>basic bank services</strong>
* Front end was created by HTML and CSS without use of bootstrap
* Connect python with SQL database to manage all information by CRUD operation
* First customer has to <strong>open their bank account</strong> by filling basic bank details such as Name, Password, DOB, mob no, Initial Deposit & register their bank account
* Now user can <strong>login</strong> account by entering <strong>user ID and password</strong>
* User can <strong>view and modify</strong> their <strong>personal details</strong> & change password also can logout acccount due to turning off the login session
* User can <strong>withdraw, credit money</strong> into their account and <strong>check current balance</strong>
* Tech stack used:`Python,Flask,MySql Database,XAMPP,html,CSS`<br>
* - [View Project Report](https://drive.google.com/file/d/1OWEpEZOMQLKn9l1bylQrqw8NeEoizxoF/view?usp=sharing)
  - [View on Github](https://share.streamlit.io/ashwinshetgaonkar/movie-rating-sentiment-analysis/main/app.py)
  
<h1><a href="https://drive.google.com/file/d/1OWEpEZOMQLKn9l1bylQrqw8NeEoizxoF/view?usp=sharing">6. Personal Web PortFolio</a></h1>
<h4><strong>HTML | CSS | BOOTSTRAP </strong></h4>  

- I have made Personal web Portfolio to showcase my <strong>skills, technical knowledge and personal projects</strong>
- üëâ<a href="https://karanchinch10.github.io/karan-chinchpure-portfolio/"><strong>Click to View My Personal Web Porfolio</strong></a> üíù

<!-- # [8.Fake News Classifier](https://github.com/ashwinshetgaonkar/Fake-News-Classifier)
* In today's world which contains a lot of digital data it will be very beneficial to have some kind of an software that will help us in descriminating between Fake and Real News with some given constraints.
* The dataset contains news instances with title and text along with its labels taken from various sources.
* My objective for this project was to train and compare the performance of various models on the basis of f1_score and time taken per prediction.
* Here I have demostrated how increasing the complexity of the model will lead to better performance but will hamper the time taken per prediction.
* Build an web app using streamlit which uses model trained using a feed forward neutral network.<br>
  [To view on kaggle](https://www.kaggle.com/code/ashwinshetgaonkar/fake-news-classifier-nb-bert),[To view the web app](https://share.streamlit.io/ashwinshetgaonkar/fake-news-classifier/main/app.py) -->
